"""Base switch class for UniFi Network Rules integration."""
from __future__ import annotations

import logging
from typing import Any, Optional, Set
import time
import asyncio

from homeassistant.components.switch import SwitchEntity
from homeassistant.core import callback
from homeassistant.helpers.entity import DeviceInfo, EntityCategory, generate_entity_id
from homeassistant.helpers.entity_registry import async_get as async_get_entity_registry
from homeassistant.helpers.update_coordinator import CoordinatorEntity
from homeassistant.helpers.dispatcher import async_dispatcher_connect, async_dispatcher_send
from homeassistant.exceptions import HomeAssistantError

from ..const import DOMAIN, MANUFACTURER, SWITCH_DELAYED_VERIFICATION_SLEEP_SECONDS
from ..coordinator import UnifiRuleUpdateCoordinator
from ..services.constants import SIGNAL_ENTITIES_CLEANUP
from ..helpers.rule import (
    get_rule_id, 
    get_rule_name, 
    get_rule_enabled,
    get_object_id,
)

LOGGER = logging.getLogger(__name__)

class UnifiRuleSwitch(CoordinatorEntity[UnifiRuleUpdateCoordinator], SwitchEntity):
    """Switch to enable/disable UniFi Network rules."""

    def __init__(
        self,
        coordinator: UnifiRuleUpdateCoordinator,
        rule_data: Any,
        rule_type: str,
        entry_id: str = None,
    ) -> None:
        """Initialize the rule switch."""
        super().__init__(coordinator)
        self._rule_data = rule_data
        self._rule_type = rule_type
        self._entry_id = entry_id
        # Set entity category as a configuration entity
        self.entity_category = EntityCategory.CONFIG
        
        # Get rule ID using helper function
        self._rule_id = get_rule_id(rule_data)
        if not self._rule_id:
            raise ValueError("Rule must have an ID")
        
        # Get rule name using helper function - rely entirely on rule.py for naming
        # Pass coordinator to get_rule_name to enable zone name lookups for FirewallPolicy objects
        self._attr_name = get_rule_name(rule_data, coordinator) or f"Rule {self._rule_id}"
        
        # Set unique_id to the rule ID directly - this is what the helper provides
        # This ensures consistency with how rules are identified throughout the integration
        self._attr_unique_id = self._rule_id
        
        # Get the object_id from our helper for consistency
        object_id = get_object_id(rule_data, rule_type)
        
        # Set the entity_id properly using generate_entity_id helper
        # This is the correct way to set a custom entity_id
        self.entity_id = generate_entity_id(
            f"{DOMAIN}.{{}}", object_id, hass=coordinator.hass
        )
        
        # Set has_entity_name to False to ensure the entity name is shown in UI
        self._attr_has_entity_name = False
        
        # Set default icon for all rule switches (can be overridden by subclasses)
        self._attr_icon = "mdi:toggle-switch"
        
        # Set device info
        self._attr_device_info = DeviceInfo(
            identifiers={(DOMAIN, coordinator.api.host)},
            name="UniFi Network Rules",
            manufacturer=MANUFACTURER,
            model="UniFi Dream Machine"
        )
        
        # Enable optimistic updates for better UX
        self._attr_assumed_state = True
        self._optimistic_state = None
        self._optimistic_timestamp = 0  # Add timestamp for optimistic state
        self._optimistic_max_age = 5  # Maximum age in seconds for optimistic state
        self._operation_pending = False
        self._last_auth_failure_time = 0
        
        # Initialize linked entity tracking
        self._linked_parent_id = None  # Unique ID of parent entity, if any
        self._linked_child_ids = set()  # Set of unique IDs of child entities

        LOGGER.debug("Initialized entity instance for unique_id=%s, entity_id=%s",
                   self._attr_unique_id, self.entity_id)

    @property
    def linked_parent_id(self) -> Optional[str]:
        """Return the unique ID of the parent entity, if this is a child entity."""
        return self._linked_parent_id
        
    @property
    def linked_child_ids(self) -> Set[str]:
        """Return the set of unique IDs of child entities."""
        return self._linked_child_ids
        
    def register_child_entity(self, child_unique_id: str) -> None:
        """Register a child entity with this entity."""
        self._linked_child_ids.add(child_unique_id)
        LOGGER.debug("Registered child entity %s with parent %s", 
                   child_unique_id, self._attr_unique_id)
                   
    def register_parent_entity(self, parent_unique_id: str) -> None:
        """Register this entity as a child of the given parent."""
        self._linked_parent_id = parent_unique_id
        LOGGER.debug("Registered entity %s as child of %s", 
                   self._attr_unique_id, parent_unique_id)
                   
    @staticmethod
    def establish_parent_child_relationship(parent: 'UnifiRuleSwitch', child: 'UnifiRuleSwitch') -> None:
        """Establish bidirectional parent-child relationship between two entities.
        
        Args:
            parent: The parent entity
            child: The child entity
        """
        parent.register_child_entity(child.unique_id)
        child.register_parent_entity(parent.unique_id)
        LOGGER.debug("Established parent-child relationship: %s â†’ %s", 
                   parent.entity_id, child.entity_id)

    def clear_optimistic_state(self, force: bool = False) -> None:
        """Clear the optimistic state if it exists.
        
        Args:
            force: If True, force clearing regardless of timestamp
        """
        if self._optimistic_state is not None:
            if force:
                LOGGER.debug("Forcibly clearing optimistic state for %s", self._rule_id)
                self._optimistic_state = None
                self._optimistic_timestamp = 0
                self._operation_pending = False
            else:
                current_time = time.time()
                age = current_time - self._optimistic_timestamp
                if age > self._optimistic_max_age:
                    LOGGER.debug("Clearing optimistic state for %s (age: %.1f seconds)",
                               self._rule_id, age)
                    self._optimistic_state = None
                    self._optimistic_timestamp = 0
                    self._operation_pending = False

    def mark_pending_operation(self, target_state: bool) -> None:
        """Mark that an operation is pending with a target state.
        
        Args:
            target_state: The target state (True for on, False for off)
        """
        self._optimistic_state = target_state
        self._optimistic_timestamp = time.time()
        self._operation_pending = True
        
    def handle_auth_failure(self) -> None:
        """Handle authentication failure by adjusting optimistic states."""
        # Record when this auth failure happened
        self._last_auth_failure_time = time.time()
        
        # Only retain optimistic state for a shorter period during auth failures
        if self._optimistic_state is not None:
            self._optimistic_max_age = 2  # Reduced maximum age during auth problems
            
        # Log that we're handling an auth failure for this entity
        LOGGER.debug("Handling auth failure for entity %s (current optimistic state: %s)",
                   self.entity_id, 
                   "on" if self._optimistic_state else "off" if self._optimistic_state is not None else "None")
        
        # Don't immediately clear optimistic state - let it expire naturally
        # This gives time for auth recovery to succeed

    @callback
    def _handle_coordinator_update(self) -> None:
        """Handle updated data from the coordinator."""
        LOGGER.debug("%s(%s): Handling coordinator update.", type(self).__name__, self.entity_id or self.unique_id)

        if not self.coordinator or not self.coordinator.data:
            LOGGER.debug("%s(%s): Coordinator or coordinator data missing, skipping update.", type(self).__name__, self.entity_id or self.unique_id)
            return

        # Get the current rule from the coordinator data
        new_rule = self._get_current_rule()
        current_availability = new_rule is not None
        LOGGER.debug("%s(%s): Rule lookup result: %s. Availability: %s",
                     type(self).__name__, self.entity_id or self.unique_id,
                     "Found" if new_rule else "Not Found",
                     current_availability)

        if new_rule is not None:
            # Store the NEW rule data
            self._rule_data = new_rule

            # --- Optimistic State Handling ---
            if self._optimistic_state is not None:
                current_time = time.time()
                age = current_time - self._optimistic_timestamp
                max_age = self._optimistic_max_age

                # Check if optimistic state expired
                if age > max_age:
                    LOGGER.debug("%s(%s): Optimistic state expired (age: %.1fs > max: %ds).",
                               type(self).__name__, self.entity_id or self.unique_id, age, max_age)

                    # Get actual state from the NEW rule data
                    actual_state = self._get_actual_state_from_rule(new_rule)
                    LOGGER.debug("%s(%s): Actual state from new rule data: %s",
                              type(self).__name__, self.entity_id or self.unique_id, actual_state)

                    # Clear optimistic state only if actual state matches or is unknown
                    if self._optimistic_state == actual_state or actual_state is None:
                        LOGGER.debug("%s(%s): Clearing optimistic state (matches actual or actual is None).",
                                    type(self).__name__, self.entity_id or self.unique_id)
                        self.clear_optimistic_state(force=True)  # Force clear here
                    else:
                        LOGGER.debug("%s(%s): State mismatch: optimistic=%s, actual=%s. Keeping optimistic state briefly.",
                                  type(self).__name__, self.entity_id or self.unique_id,
                                  self._optimistic_state, actual_state)

            # Clear operation pending flag if not cleared by optimistic logic
            if self._operation_pending and self._optimistic_state is None:
                LOGGER.debug("%s(%s): Clearing pending operation flag as optimistic state is now None.",
                           type(self).__name__, self.entity_id or self.unique_id)
                self._operation_pending = False

        else:
            # --- Rule Not Found ---
            LOGGER.debug("%s(%s): Rule not found in coordinator data. Initiating removal.",
                       type(self).__name__, self.entity_id or self.unique_id)
            # Ensure internal data reflects disappearance
            self._rule_data = None
            # Clear any lingering optimistic state
            self.clear_optimistic_state(force=True)
            # Mark as unavailable immediately
            self._attr_available = False
            # Proactively trigger the removal process - This is already in the event loop
            self.hass.async_create_task(self.async_initiate_self_removal())
            # Write state to reflect unavailability before removal completes
            self.async_write_ha_state()
            return # Exit early as the entity is being removed

        # Write the state AFTER processing coordinator update if not removing
        LOGGER.debug("%s(%s): Writing HA state after coordinator update.", type(self).__name__, self.entity_id or self.unique_id)
        self.async_write_ha_state()

    def _get_actual_state_from_rule(self, rule: Any) -> Optional[bool]:
        """Helper to get the actual state from a rule object, handling different types."""
        # Default implementation for most rules
        if hasattr(rule, 'enabled'):
            return getattr(rule, 'enabled')
        # Handle raw dict case if needed
        if isinstance(rule, dict) and 'enabled' in rule:
            return rule.get('enabled')
        LOGGER.warning("%s(%s): Could not determine actual state from rule object type %s",
                     type(self).__name__, self.entity_id or self.unique_id, type(rule).__name__)
        return None # Return None if state cannot be determined

    @property
    def available(self) -> bool:
        """Return if entity is available."""
        # If parent entity is linked, base availability on parent
        if self._linked_parent_id:
            # Find parent entity by unique ID
            parent_entity_id = None
            entity_registry = async_get_entity_registry(self.hass)
            if entity_registry:
                parent_entity_id = entity_registry.async_get_entity_id("switch", DOMAIN, self._linked_parent_id)

            if parent_entity_id:
                parent_state = self.hass.states.get(parent_entity_id)
                # Check if parent state exists and is not unavailable
                parent_state_available = parent_state and parent_state.state != "unavailable"

                parent_is_available = parent_state_available
                if parent_is_available:
                    # Check the parent entity object's available property if possible
                    parent_entity = self.hass.data.get(DOMAIN, {}).get(DOMAIN, {}).get(parent_entity_id)
                    if parent_entity and hasattr(parent_entity, 'available'):
                        try:
                            # Use a flag to prevent infinite recursion if parent also checks child
                            if getattr(self, '_checking_parent_availability', False):
                                parent_is_truly_available = True  # Assume true to break loop
                            else:
                                setattr(parent_entity, '_checking_parent_availability', True)
                                parent_is_truly_available = parent_entity.available
                                delattr(parent_entity, '_checking_parent_availability')
                            if not parent_is_truly_available:
                                return False  # If parent object says it's not available, we aren't either
                        except Exception as e:
                            LOGGER.warning("%s(%s): Error checking parent entity availability property: %s", 
                                          type(self).__name__, self.entity_id, e)
                    return True
                else:
                    return False

        # Standard availability check (if not a child or parent lookup failed)
        coord_success = self.coordinator.last_update_success
        current_rule = self._get_current_rule()
        rule_exists = current_rule is not None
        is_available = coord_success and rule_exists

        return is_available

    @property
    def is_on(self) -> bool:
        """Return the enabled state of the rule."""
        # Use optimistic state if set
        if self._optimistic_state is not None:
            return self._optimistic_state

        rule = self._get_current_rule()
        if rule is None:
            return False

        return get_rule_enabled(rule)

    @property
    def assumed_state(self) -> bool:
        """Return False to get toggle slider UI instead of icon buttons."""
        return False

    def _get_current_rule(self) -> Any | None:
        """Get current rule data from coordinator."""
        try:
            if not self.coordinator or not self.coordinator.data or self._rule_type not in self.coordinator.data:
                return None

            rules = self.coordinator.data.get(self._rule_type, [])
            
            found_rule = None
            for rule in rules:
                current_rule_id = get_rule_id(rule)
                if current_rule_id == self._rule_id:
                    found_rule = rule
                    break # Exit loop once found

            return found_rule
        except Exception as err:
            LOGGER.error("%s(%s): Error getting rule data in _get_current_rule: %s", 
                        type(self).__name__, self.entity_id or self._rule_id, err)
            return None

    def _to_dict(self, obj: Any) -> dict:
        """Convert a rule object to a dictionary."""
        # Handle objects with raw property (aiounifi API objects and FirewallRule)
        if hasattr(obj, "raw") and isinstance(obj.raw, dict):
            return obj.raw.copy()
        
        # Handle plain dictionaries
        if isinstance(obj, dict):
            return obj.copy()
            
        # Handle other objects by creating a dict from properties
        # Get the rule ID properly considering object type
        rule_id = None
        if hasattr(obj, "id"):
            rule_id = getattr(obj, "id")
            
        base_data = {
            "_id": rule_id,
            "enabled": getattr(obj, "enabled", False)
        }
        
        # Include other common attributes if they exist
        for attr in ["name", "description", "action"]:
            if hasattr(obj, attr):
                base_data[attr] = getattr(obj, attr)
        
        return {k: v for k, v in base_data.items() if v is not None}

    async def async_turn_on(self, **kwargs: Any) -> None:
        """Turn on (enable) the rule."""
        await self._async_toggle_rule(True)

    async def async_turn_off(self, **kwargs: Any) -> None:
        """Turn off (disable) the rule."""
        await self._async_toggle_rule(False)

    def turn_on(self, **kwargs: Any) -> None:
        """Turn on (enable) the rule - synchronous wrapper."""
        if self.hass and self.hass.loop and self.hass.loop.is_running():
            asyncio.create_task(self.async_turn_on(**kwargs))

    def turn_off(self, **kwargs: Any) -> None:
        """Turn off (disable) the rule - synchronous wrapper."""
        if self.hass and self.hass.loop and self.hass.loop.is_running():
            asyncio.create_task(self.async_turn_off(**kwargs))

    async def _async_toggle_rule(self, enable: bool) -> None:
        """Handle toggling the rule state."""
        action_type = "Turning on" if enable else "Turning off"
        LOGGER.debug("%s rule %s (%s)", action_type, self._rule_id, self._rule_type)
        
        # Set optimistic state first for immediate UI feedback with timestamp
        self.mark_pending_operation(enable)
        
        # Write state and force an update to ensure all clients receive it immediately
        self.async_write_ha_state()
        
        # Get the current rule object
        current_rule = self._get_current_rule()
        if current_rule is None:
            LOGGER.error("Rule not found in coordinator data: %s", self._rule_id)
            # Revert optimistic state
            self.mark_pending_operation(not enable)
            self.async_write_ha_state()
            return
        
        # Initialize pending operations dict if needed
        if not hasattr(self.coordinator, "_pending_operations"):
            self.coordinator._pending_operations = {}
            
        # Add this entity's ID to pending operations with target state
        self.coordinator._pending_operations[self._rule_id] = enable
        
        LOGGER.debug("Adding rule %s to pending operations queue with target state: %s", 
                   self._rule_id, enable)
        
        # Register the operation with the coordinator to prevent redundant refreshes.
        change_type = "enabled" if enable else "disabled"
        entity_id = self.entity_id or f"switch.{self._rule_id}"
        self.coordinator.register_ha_initiated_operation(self._rule_id, entity_id, change_type)
        
        # Define callback to handle operation completion
        async def handle_operation_complete(future):
            """Handle operation completion."""
            try:
                success = future.result()
                
                if not success:
                    # Revert optimistic state if failed
                    LOGGER.error("Failed to %s rule %s", 
                                "enable" if enable else "disable", self._rule_id)
                    self.mark_pending_operation(not enable)
                    self.async_write_ha_state()
                else:
                    # On success, refresh the optimistic state timestamp to prevent premature clearing
                    self._optimistic_timestamp = time.time()
                    self.async_write_ha_state()

                    # --- Smart Verification Task ---
                    # This task acts as a safety net. It waits a few seconds and then checks
                    # if the change was confirmed by the trigger system (which consumes the
                    # HA-initiated operation flag). If not, it forces a refresh.
                    async def delayed_verification():
                        await asyncio.sleep(SWITCH_DELAYED_VERIFICATION_SLEEP_SECONDS) # Wait 7 seconds for smart polling update
                        if self.coordinator.check_and_consume_ha_initiated_operation(self._rule_id):
                            # If the flag was still present, it means the trigger system
                            # did NOT get a change event. We must refresh.
                            LOGGER.warning("Delayed verification: Trigger did not receive change event for %s. Forcing refresh.", self._rule_id)
                            await self.coordinator.async_request_refresh()
                        else:
                            # The flag was already consumed, so the trigger worked correctly.
                            LOGGER.debug("Delayed verification: Trigger confirmed change for %s. No refresh needed.", self._rule_id)
                    
                    # Skip delayed verification for device LED toggles since we use immediate trigger + polling detection
                    if self._rule_type != "devices":
                        self.hass.async_create_task(delayed_verification())
                
            except Exception as err:
                # Check if this is an auth error
                error_str = str(err).lower()
                if "401 unauthorized" in error_str or "403 forbidden" in error_str:
                    LOGGER.warning("Authentication error in toggle operation for rule %s: %s", 
                                 self._rule_id, err)
                    # Report auth failure to handle it appropriately
                    self.handle_auth_failure()
                else:
                    LOGGER.error("Error in toggle operation for rule %s: %s", 
                                self._rule_id, err)
                
                # Revert optimistic state on error
                self.mark_pending_operation(not enable)
                self.async_write_ha_state()
            finally:
                # Always remove from pending operations when complete
                if self._rule_id in self.coordinator._pending_operations:
                    LOGGER.debug("Removing rule %s from pending operations after completion", 
                               self._rule_id)
                    del self.coordinator._pending_operations[self._rule_id]
        
        # Queue the appropriate toggle operation based on rule type
        try:
            # Select the appropriate toggle function
            toggle_func = None
            if self._rule_type == "firewall_policies":
                toggle_func = self.coordinator.api.toggle_firewall_policy
            elif self._rule_type == "traffic_rules":
                toggle_func = self.coordinator.api.toggle_traffic_rule
            elif self._rule_type == "port_forwards":
                toggle_func = self.coordinator.api.toggle_port_forward
            elif self._rule_type == "traffic_routes":
                toggle_func = self.coordinator.api.toggle_traffic_route
            elif self._rule_type == "static_routes":
                toggle_func = self.coordinator.api.toggle_static_route
            elif self._rule_type == "legacy_firewall_rules":
                toggle_func = self.coordinator.api.toggle_legacy_firewall_rule
            elif self._rule_type == "wlans":
                toggle_func = self.coordinator.api.toggle_wlan
            elif self._rule_type == "qos_rules":
                toggle_func = self.coordinator.api.toggle_qos_rule
            elif self._rule_type == "vpn_clients":
                toggle_func = self.coordinator.api.toggle_vpn_client
            elif self._rule_type == "vpn_servers":
                toggle_func = self.coordinator.api.toggle_vpn_server
            elif self._rule_type == "nat_rules":
                toggle_func = self.coordinator.api.toggle_nat_rule
            elif self._rule_type == "port_profiles":
                async def port_profile_toggle_wrapper(profile_obj):
                    # When enabling, provide a native_networkconf_id if missing by
                    # using coordinator.networks preference. The API function itself
                    # will also try to discover a default if needed, but we prefer
                    # to choose deterministically here.
                    native_id = None
                    try:
                        # If current state is disabled, supply target native id
                        current = self._get_current_rule()
                        is_currently_on = bool(current and getattr(current, 'enabled', False))
                        if not is_currently_on and hasattr(self.coordinator, 'networks'):
                            networks = self.coordinator.networks or []
                            # Prefer corporate/LAN
                            preferred = next((n for n in networks if getattr(n, 'purpose', '') == 'corporate'), None)
                            if not preferred and networks:
                                preferred = networks[0]
                            native_id = preferred.id if preferred else None
                    except Exception:
                        native_id = None
                    return await self.coordinator.api.toggle_port_profile(profile_obj, native_id)
                toggle_func = port_profile_toggle_wrapper
            elif self._rule_type == "devices":
                # For device LED toggles, use a special wrapper function
                async def led_toggle_wrapper(device, state):
                    """Wrapper to make LED toggle compatible with queue system."""
                    return await self.coordinator.api.set_device_led(device, state)
                toggle_func = led_toggle_wrapper
            else:
                raise ValueError(f"Unknown rule type: {self._rule_type}")
            
            # Queue the operation (special handling for devices)
            if self._rule_type == "devices":
                # For LED toggles, pass the enable state as the second parameter
                future = await self.coordinator.api.queue_api_operation(toggle_func, current_rule, enable)
            else:
                # For regular rules, pass just the rule object
                future = await self.coordinator.api.queue_api_operation(toggle_func, current_rule)
            
            # Add the completion callback
            future.add_done_callback(
                lambda f: self.hass.async_create_task(handle_operation_complete(f))
            )
            
            LOGGER.debug("Successfully queued toggle operation for rule %s", self._rule_id)
        except Exception as err:
            LOGGER.error("Failed to queue toggle operation for rule %s: %s", 
                         self._rule_id, err)
            # Remove from pending operations if queueing failed
            if self._rule_id in self.coordinator._pending_operations:
                del self.coordinator._pending_operations[self._rule_id]
            
            # Revert optimistic state
            self.mark_pending_operation(not enable)
            self.async_write_ha_state()

    async def async_will_remove_from_hass(self) -> None:
        """Handle entity cleanup when removed from Home Assistant."""
        LOGGER.debug("Entity %s cleaning up before removal from Home Assistant", self.entity_id)

        # Clean up internal entity tracking dictionary
        entity_dict = self.hass.data.get(DOMAIN, {}).get('entities', {})
        if self.entity_id in entity_dict:
            del entity_dict[self.entity_id]
            LOGGER.debug("Removed %s from internal entity tracking.", self.entity_id)

        # Clean up global _CREATED_UNIQUE_IDS set (if still used)
        from .setup import _CREATED_UNIQUE_IDS
        _CREATED_UNIQUE_IDS.discard(self._attr_unique_id) # Use discard for safety

        # IMPORTANT: Call super().async_will_remove_from_hass() LAST
        # This ensures base class cleanup (like removing listeners registered with self.async_on_remove) happens.
        await super().async_will_remove_from_hass()
        LOGGER.debug("Finished async_will_remove_from_hass for %s", self.entity_id)

    @callback
    def _handle_entity_removal(self, removed_entity_id: str) -> None:
        """Handle the removal of an entity via dispatcher signal."""
        # This function is primarily for reacting to EXTERNAL removal signals.
        # Proactive removal initiated by _handle_coordinator_update uses async_initiate_self_removal.
        if removed_entity_id != self._rule_id:
            return

        LOGGER.info("Received external removal signal for entity %s (%s). Initiating cleanup.",
                   self.entity_id, self._rule_id)
        # Avoid duplicate removal if already initiated
        if getattr(self, '_removal_initiated', False):
            LOGGER.debug("Removal already initiated for %s, skipping signal handler.", self.entity_id)
            return

        # Initiate removal asynchronously in a thread-safe way
        self.hass.loop.call_soon_threadsafe(
            self.hass.async_create_task,
            self.async_initiate_self_removal()
        )

    async def async_initiate_self_removal(self) -> None:
        """Proactively remove this entity and its children from Home Assistant."""
        from .setup import _CREATED_UNIQUE_IDS
        entity_id_for_log = self.entity_id or self._attr_unique_id

        if getattr(self, '_removal_initiated', False):
            return

        self._removal_initiated = True # Set flag to prevent loops

        entity_registry = async_get_entity_registry(self.hass)

        # 0. Always remove from coordinator known_unique_ids first to prevent recreation
        if hasattr(self.coordinator, 'known_unique_ids'):
            self.coordinator.known_unique_ids.discard(self._attr_unique_id)

        # Also remove from global tracking set immediately
        _CREATED_UNIQUE_IDS.discard(self._attr_unique_id)

        # 1. Remove Child Entities RECURSIVELY
        if self._linked_child_ids:
            children_to_remove = list(self._linked_child_ids)
            for child_unique_id in children_to_remove:
                child_entity_id = entity_registry.async_get_entity_id("switch", DOMAIN, child_unique_id)
                child_entity = None
                if child_entity_id:
                    # Look up child entity instance from hass.data
                    child_entity = self.hass.data.get(DOMAIN, {}).get('entities', {}).get(child_entity_id)

                if child_entity and hasattr(child_entity, 'async_initiate_self_removal'):
                    try:
                        await child_entity.async_initiate_self_removal()
                    except Exception as child_err:
                        LOGGER.error("%s(%s): Error requesting self-removal for child entity %s (%s): %s",
                                     type(self).__name__, entity_id_for_log, child_entity_id or child_unique_id, child_unique_id, child_err)
                else:
                    # Fallback: Child object not found or doesn't have the method. Remove directly from registry.
                    if child_entity_id and entity_registry.async_get(child_entity_id):
                        try:
                            entity_registry.async_remove(child_entity_id)
                        except Exception as reg_rem_err:
                            LOGGER.error("%s(%s): Error removing child %s from registry directly: %s",
                                         type(self).__name__, entity_id_for_log, child_entity_id, reg_rem_err)
                    # Also clean up tracking even if registry removal fails or wasn't needed
                    if hasattr(self.coordinator, 'known_unique_ids'):
                        self.coordinator.known_unique_ids.discard(child_unique_id)
                    _CREATED_UNIQUE_IDS.discard(child_unique_id) # Use discard

                # Remove from parent's list regardless of success/failure of child removal
                self._linked_child_ids.discard(child_unique_id)

        # 3. Remove Self from Entity Registry and HA Core
        entity_id_to_remove = self.entity_id # Store current entity_id for logging
        LOGGER.debug("%s(%s): Preparing to call self.async_remove(force_remove=True) for entity_id: %s",
                     type(self).__name__, entity_id_for_log, entity_id_to_remove)
        try:
            await self.async_remove(force_remove=True)
            LOGGER.info("%s(%s): Successfully completed self.async_remove() for entity_id: %s.",
                         type(self).__name__, entity_id_for_log, entity_id_to_remove)
        except Exception as remove_err:
            # Log expected errors during removal less severely
            if isinstance(remove_err, HomeAssistantError) and "Entity not found" in str(remove_err):
                LOGGER.debug("%s(%s): Entity %s already removed from HA core.",
                             type(self).__name__, entity_id_for_log, entity_id_to_remove)
            else:
                LOGGER.error("%s(%s): Error during final async_remove for entity_id %s: %s",
                             type(self).__name__, entity_id_for_log, entity_id_to_remove, remove_err)
                LOGGER.exception("%s(%s): Exception during async_remove for entity_id %s:",
                                 type(self).__name__, entity_id_for_log, entity_id_to_remove)

    async def async_added_to_hass(self) -> None:
        """When entity is added to hass."""
        from .setup import _CREATED_UNIQUE_IDS  # Add global declaration here

        await super().async_added_to_hass()

        # Store entity in a central place for easy lookup (e.g., by parent/child logic)
        if DOMAIN not in self.hass.data:
            self.hass.data[DOMAIN] = {}
        if 'entities' not in self.hass.data[DOMAIN]:
            self.hass.data[DOMAIN]['entities'] = {}
        self.hass.data[DOMAIN]['entities'][self.entity_id] = self
        LOGGER.debug("Stored entity %s in hass.data[%s]['entities']", self.entity_id, DOMAIN)

        # Perform global unique ID tracking here
        if self.unique_id in _CREATED_UNIQUE_IDS:
             # This case should ideally not happen if setup_entry filtering works,
            # but log if it does.
            LOGGER.warning("Entity %s added to HASS, but unique_id %s was already tracked.",
                           self.entity_id, self.unique_id)
        else:
            _CREATED_UNIQUE_IDS.add(self.unique_id)
            LOGGER.debug("Added unique_id %s to global tracking upon adding entity %s to HASS.",
                         self.unique_id, self.entity_id)

        # Add update callbacks
        self.async_on_remove(
            self.coordinator.async_add_listener(self._handle_coordinator_update)
        )

        # Also listen for specific events related to this entity
        self.async_on_remove(
            async_dispatcher_connect(
                self.hass,
                f"{DOMAIN}_entity_update_{self._rule_id}",
                self.async_schedule_update_ha_state
            )
        )

        # Listen for authentication failure events
        self.async_on_remove(
            async_dispatcher_connect(
                self.hass,
                f"{DOMAIN}_auth_failure",
                self._handle_auth_failure_event
            )
        )

        # Listen for authentication restored events
        self.async_on_remove(
            async_dispatcher_connect(
                self.hass,
                f"{DOMAIN}_auth_restored",
                self._handle_auth_restored_event
            )
        )

        # Listen for entity created events
        self.async_on_remove(
            async_dispatcher_connect(
                self.hass,
                f"{DOMAIN}_entity_created",
                self._handle_entity_created
            )
        )

        # Listen for force cleanup signal
        self.async_on_remove(
            async_dispatcher_connect(
                self.hass,
                SIGNAL_ENTITIES_CLEANUP,
                self._handle_force_cleanup
            )
        )

        # --- Ensure initial state is based on current coordinator data --- 

        # Make sure the entity is properly registered in the entity registry
        try:
            registry = async_get_entity_registry(self.hass)

            # Log the entity registry state
            LOGGER.debug("Entity registry check - unique_id: %s, entity_id: %s",
                      self.unique_id, self.entity_id)

            # Check if the entity already exists in the registry
            existing_entity = registry.async_get_entity_id("switch", DOMAIN, self.unique_id)

            if existing_entity:
                LOGGER.debug("Entity already exists in registry: %s", existing_entity)
                # Don't try to update the entity_id - this has been causing problems
                # Just force a state update to ensure it's current
            else:
                # Register the entity with our consistent ID format
                try:
                    # Use the object_id from rule.py
                    object_id = get_object_id(self._rule_data, self._rule_type)

                    entity_entry = registry.async_get_or_create(
                        "switch",
                        DOMAIN,
                        self.unique_id,
                        suggested_object_id=object_id,
                        # Don't set disabled_by to ensure it's enabled
                        disabled_by=None,
                    )

                    if entity_entry:
                        LOGGER.info("Entity registered in registry: %s", entity_entry.entity_id)
                    else:
                        LOGGER.warning("Failed to register entity with registry")
                except Exception as reg_err:
                    LOGGER.warning("Could not register entity: %s", reg_err)

            # Force a state update to ensure it shows up AFTER potentially registering
            self.async_write_ha_state()
        except Exception as err:
            LOGGER.error("Error during entity registration: %s", err)

    @callback
    def _handle_auth_failure_event(self, _: Any = None) -> None:
        """Handle authentication failure event."""
        LOGGER.debug("Authentication failure event received for entity %s", self.entity_id)
        
        # Track the auth failure time
        self._last_auth_failure_time = time.time()
        
        # Notify the entity to handle auth failure appropriately
        self.handle_auth_failure()
        
        # Force a state update to reflect any changes
        self.async_write_ha_state()
        
    @callback
    def _handle_auth_restored_event(self, _: Any = None) -> None:
        """Handle authentication restored event."""
        LOGGER.debug("Authentication restored event received for entity %s", self.entity_id)
        
        # Reset auth failure time
        self._last_auth_failure_time = 0
        
        # Reset optimistic max age to normal
        self._optimistic_max_age = 5
        
        # If we have an operation pending and optimistic state is set, keep it longer
        # to allow time for the next refresh to verify state
        if self._operation_pending and self._optimistic_state is not None:
            self._optimistic_timestamp = time.time()
            LOGGER.debug("Refreshed optimistic state timestamp due to auth restoration")
        else:
            # No operations pending, clear any lingering optimistic state
            self.clear_optimistic_state()
        
        # Force an update
        self.async_schedule_update_ha_state(True)

    @callback
    def _handle_entity_created(self) -> None:
        """Handle entity created event."""
        LOGGER.debug("Entity created event received for %s", self.entity_id)
        
        # Force a state update
        self.async_write_ha_state()
        
        # Use a dispatcher instead of trying to call async_update_entity directly
        async_dispatcher_send(self.hass, f"{DOMAIN}_entity_update_{self.unique_id}")

    @callback
    def _handle_force_cleanup(self, _: Any = None) -> None:
        """Handle force cleanup signal."""
        LOGGER.debug("Force cleanup signal received for entity %s", self.entity_id)
        # Force an update to synchronize with latest data
        self.async_schedule_update_ha_state(True)
